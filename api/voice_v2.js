// api/voice_v2.js - Version avec Hugging Face Whisper pour l'hÃ©breu + logs dÃ©taillÃ©s
import { google } from "googleapis";
import twilio from "twilio";
import * as chrono from "chrono-node";
import OpenAI from "openai";
import fetch from "node-fetch";
import fs from "fs";
import path from "path";
import { transliterate as transliterateHebrew } from "hebrew-transliteration";

const VoiceResponse = twilio.twiml.VoiceResponse;
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

/* ---------- Utils + Logging ---------- */
const sleep = (ms) => new Promise((r) => setTimeout(r, ms));

// Helper pour logs avec timestamp
function logWithTime(message, ...args) {
    const timestamp = new Date().toISOString();
    console.log(`[${timestamp}] ${message}`, ...args);
}

// Helper pour mesurer le temps d'exÃ©cution
function timeStart(label) {
    const start = Date.now();
    logWithTime(`â±ï¸ START: ${label}`);
    return function timeEnd() {
        const duration = Date.now() - start;
        logWithTime(`â±ï¸ END: ${label} (${duration}ms / ${(duration/1000).toFixed(2)}s)`);
        return duration;
    };
}

/* ---------- Google Calendar Auth ---------- */
function getOAuthClient() {
    const credentials = JSON.parse(process.env.GOOGLE_CREDENTIALS_JSON);
    const token = JSON.parse(process.env.GOOGLE_TOKEN_JSON);
    const { client_secret, client_id, redirect_uris } =
    credentials.installed || credentials.web;

    const firstRedirectUri =
        Array.isArray(redirect_uris) && redirect_uris.length > 0 ?
        redirect_uris[0] :
        "https://developers.google.com/oauthplayground";

    const oAuth2Client = new google.auth.OAuth2(
        client_id,
        client_secret,
        firstRedirectUri
    );
    oAuth2Client.setCredentials(token);
    return oAuth2Client;
}

async function createCalendarEvent({ summary, startISO, minutes, phone }) {
    const timer = timeStart("Calendar Event Creation");
    logWithTime("ğŸ“… Creating event:", summary, startISO);
    const auth = getOAuthClient();
    const calendar = google.calendar({ version: "v3", auth });
    const start = new Date(startISO);
    const end = new Date(start.getTime() + minutes * 60000);

    const event = {
        summary,
        description: `RDV automatique â€“ patient : ${phone}`,
        start: { dateTime: start.toISOString(), timeZone: process.env.CLINIC_TIMEZONE },
        end: { dateTime: end.toISOString(), timeZone: process.env.CLINIC_TIMEZONE },
    };

    await calendar.events.insert({
        calendarId: process.env.DEFAULT_CALENDAR_ID,
        requestBody: event,
    });

    timer();
    logWithTime("âœ… Event created successfully");
    return event;
}

/* ---------- Hugging Face Whisper (gratuit, open source) ---------- */
async function transcribeWithHuggingFace(audioFile, language = "he") {
    const timer = timeStart("Hugging Face Whisper Transcription");
    try {
        logWithTime("ğŸ¤— METHOD: Hugging Face Whisper (open source)");
        logWithTime(`ğŸ“‹ Language: ${language === "he" ? "Hebrew" : "English"}`);

        const hfToken = process.env.HUGGINGFACE_API_KEY || "";
        const hasToken = !!hfToken;
        logWithTime(`ğŸ”‘ API Key: ${hasToken ? "âœ… Present" : "âš ï¸ Not set (using free tier with rate limit)"}`);

        const model = language === "he" ? "openai/whisper-small" : "openai/whisper-base";
        logWithTime(`ğŸ¤– Model: ${model}`);

        const readTimer = timeStart("Reading audio file");
        const audioBytes = fs.readFileSync(audioFile);
        const fileSize = (audioBytes.length / 1024).toFixed(2);
        readTimer();
        logWithTime(`ğŸ“ Audio file size: ${fileSize} KB`);

        const headers = {};
        if (hfToken) {
            headers['Authorization'] = `Bearer ${hfToken}`;
        }

        const apiTimer = timeStart("Hugging Face API call");
        logWithTime(`ğŸŒ API URL: https://api-inference.huggingface.co/models/${model}`);

        const response = await fetch(
            `https://api-inference.huggingface.co/models/${model}`, {
                method: 'POST',
                headers: headers,
                body: audioBytes,
            }
        );

        const apiDuration = apiTimer();
        logWithTime(`ğŸ“¡ API Response status: ${response.status} ${response.statusText}`);

        if (!response.ok) {
            if (response.status === 503) {
                const errorData = await response.json().catch(() => ({}));
                const estimatedTime = errorData.estimated_time || 10;
                logWithTime(`â³ Model is loading, estimated wait time: ${estimatedTime}s`);
                await sleep(estimatedTime * 1000);
                timer();
                return await transcribeWithHuggingFace(audioFile, language);
            }
            const errorText = await response.text();
            logWithTime(`âŒ API Error: ${response.status} - ${errorText}`);
            timer();
            throw new Error(`Hugging Face STT error: ${response.status} - ${errorText}`);
        }

        const parseTimer = timeStart("Parsing API response");
        const data = await response.json();
        parseTimer();

        const transcription = data.text || (data[0] && data[0].text) || (Array.isArray(data) && data[0] && data[0].transcription);

        if (transcription) {
            const totalDuration = timer();
            logWithTime("âœ… SUCCESS: Hugging Face Whisper transcription completed");
            logWithTime(`ğŸ“ TRANSCRIPTION TEXT: "${transcription}"`);
            logWithTime(`ğŸ“Š Total transcription time: ${totalDuration}ms (${(totalDuration/1000).toFixed(2)}s)`);
            return transcription;
        }

        timer();
        logWithTime("âš ï¸ No transcription found in response");
        logWithTime("ğŸ“¦ Full API response:", data);
        return null;
    } catch (err) {
        timer();
        logWithTime(`ğŸš¨ ERROR: Hugging Face STT failed - ${err.message}`);
        logWithTime("ğŸ“š Error stack:", err.stack);
        return null;
    }
}

/* ---------- Twilio recording -> Whisper (HE) ---------- */
async function transcribeAudioFromTwilio(recordingUrl) {
    const totalTimer = timeStart("Complete Transcription Process");
    try {
        logWithTime("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
        logWithTime("ğŸ™ï¸ STARTING TRANSCRIPTION");
        logWithTime("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
        logWithTime(`ğŸ”— Recording URL: ${recordingUrl}`);

        const auth = Buffer.from(
            `${process.env.TWILIO_ACCOUNT_SID}:${process.env.TWILIO_AUTH_TOKEN}`
        ).toString("base64");

        const url = `${recordingUrl}.wav`;
        logWithTime(`ğŸ“¥ Download URL: ${url}`);

        const downloadTimer = timeStart("Downloading recording from Twilio");
        const delays = [200, 400, 800]; // TrÃ¨s rapides pour minimiser la latence
        let resp;
        let downloadAttempts = 0;

        for (let attempt = 0; attempt < delays.length; attempt++) {
            downloadAttempts++;
            const attemptTimer = timeStart(`Download attempt ${downloadAttempts}`);
            resp = await fetch(url, { headers: { Authorization: `Basic ${auth}` } });
            attemptTimer();

            logWithTime(`ğŸ“¡ Download attempt ${downloadAttempts}/${delays.length} - Status: ${resp.status}`);

            if (resp.ok) {
                logWithTime("âœ… Recording downloaded successfully");
                break;
            }

            if (attempt < delays.length - 1) {
                logWithTime(`â³ Waiting ${delays[attempt]}ms before retry`);
                await sleep(delays[attempt]);
            }
        }

        const downloadDuration = downloadTimer();
        logWithTime(`ğŸ“Š Download completed in ${downloadDuration}ms`);

        if (!resp || !resp.ok) {
            logWithTime(`âŒ Failed to download recording after ${downloadAttempts} attempts`);
            totalTimer();
            throw new Error(`âŒ Failed to download: ${resp?.status}`);
        }

        const saveTimer = timeStart("Saving recording to disk");
        const tempFile = path.join("/tmp", `recording-v2-${Date.now()}.wav`);
        const buffer = await resp.arrayBuffer();
        fs.writeFileSync(tempFile, Buffer.from(buffer));
        const fileSize = (buffer.byteLength / 1024).toFixed(2);
        saveTimer();
        logWithTime(`ğŸ’¾ Recording saved: ${tempFile}`);
        logWithTime(`ğŸ“ File size: ${fileSize} KB`);

        logWithTime("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
        logWithTime("ğŸ¤— USING HUGGING FACE WHISPER (FREE & FAST)");
        logWithTime("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");

        const transcription = await transcribeWithHuggingFace(tempFile, "he");

        const cleanupTimer = timeStart("Cleaning up temp file");
        fs.unlinkSync(tempFile);
        cleanupTimer();
        logWithTime("ğŸ—‘ï¸ Temp file deleted");

        const totalDuration = totalTimer();
        logWithTime("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
        if (transcription) {
            logWithTime("âœ… TRANSCRIPTION COMPLETED SUCCESSFULLY");
            logWithTime(`ğŸ“ FINAL TRANSCRIPTION: "${transcription}"`);
        } else {
            logWithTime("âŒ TRANSCRIPTION FAILED - No result");
        }
        logWithTime(`â±ï¸ TOTAL PROCESS TIME: ${totalDuration}ms (${(totalDuration/1000).toFixed(2)}s)`);
        logWithTime("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");

        return transcription || "";
    } catch (err) {
        totalTimer();
        logWithTime("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
        logWithTime("ğŸš¨ TRANSCRIPTION PROCESS ERROR");
        logWithTime(`âŒ Error: ${err.message}`);
        logWithTime("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
        return "";
    }
}

/* ---------- Main Twilio Webhook ---------- */
export default async function handler(req, res) {
    const requestTimer = timeStart("Total Request Handler");

    logWithTime("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    logWithTime("ğŸŸ¢ NEW REQUEST");
    logWithTime("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    logWithTime("ğŸ”¹ STEP:", req.query.step || "start");
    logWithTime("ğŸ”¹ METHOD:", req.method);
    logWithTime("ğŸ”¹ BODY keys:", Object.keys(req.body || {}));
    logWithTime("ğŸ”¹ Query params:", req.query);

    if (req.method !== "POST") {
        logWithTime("âŒ Method not allowed:", req.method);
        return res.status(405).send("Method Not Allowed");
    }

    const vr = new VoiceResponse();
    const step = req.query.step || "start";

    try {
        /* ---- STEP 1 : Language Selection ---- */
        if (step === "start") {
            logWithTime("ğŸ“ STEP 1: Language Selection");
            const gather = vr.gather({
                input: "speech dtmf",
                numDigits: 1,
                action: "https://dentist-ivr-poc.vercel.app/api/voice_v2?step=lang",
                method: "POST",
                speechTimeout: "auto",
                timeout: 10,
                bargeIn: true,
            });

            gather.say({ language: "en-US" }, "For service in English, press 1.");
            gather.say({ language: "fr-FR" }, "Pour le service en franÃ§ais, appuyez sur 2.");
            // HÃ©breu via MP3 prÃ©-enregistrÃ© (Twilio ne supporte pas he-IL en TTS)
            gather.play("https://dentist-ivr-poc.vercel.app/audio/press-3-he.mp3");

            logWithTime("âœ… Sending language selection TwiML");
            requestTimer();
            res.setHeader("Content-Type", "text/xml");
            res.send(vr.toString());
            return;
        }

        /* ---- STEP 2 : Ask Name + Date ---- */
        if (step === "lang") {
            logWithTime("ğŸ“ STEP 2: Language Selected, Asking for Name + Date");
            const digits = req.body.Digits;
            const speech = (req.body.SpeechResult || "").toLowerCase();
            logWithTime(`ğŸ”¢ Digits: ${digits}`);
            logWithTime(`ğŸ—£ï¸ Speech: ${speech}`);

            let key = "1"; // EN by default
            if (digits === "2" || speech.includes("fran")) key = "2";
            else if (digits === "3" || speech.includes("ivrit") || speech.includes("×¢×‘×¨×™×ª")) key = "3";

            logWithTime(`ğŸŒ Selected language: ${key === "1" ? "English" : key === "2" ? "French" : "Hebrew"}`);

            const langs = { "1": "en-US", "2": "fr-FR" };

            if (key === "3") {
                // Mode hÃ©breu: on joue l'audio et on enregistre (pas de STT Twilio)
                logWithTime("ğŸµ Playing Hebrew welcome MP3");
                vr.play("https://dentist-ivr-poc.vercel.app/audio/welcome-he.mp3");
                vr.record({
                    action: `https://dentist-ivr-poc.vercel.app/api/voice_v2?step=collect&lang=3`,
                    method: "POST",
                    maxLength: "60",
                    timeout: "6",
                    trim: "do-not-trim",
                    playBeep: false,
                    finishOnKey: "#",
                });
                logWithTime("ğŸ™ï¸ Recording Hebrew audio for Whisper transcription");
            } else {
                // EN / FR : Gather STT Twilio
                const prompts = {
                    "1": "Welcome to Doctor B's clinic. Please say your name and the date and time you'd like for your appointment.",
                    "2": "Bienvenue au cabinet du docteur B. Veuillez indiquer votre nom ainsi que la date et l'heure souhaitÃ©es pour votre rendez-vous.",
                };

                logWithTime(`ğŸ“¢ Playing prompt: "${prompts[key]}"`);

                const gather = vr.gather({
                    input: "speech",
                    action: `https://dentist-ivr-poc.vercel.app/api/voice_v2?step=collect&lang=${key}`,
                    method: "POST",
                    language: langs[key],
                    speechTimeout: "auto",
                    timeout: 60,
                    bargeIn: true,
                });

                gather.say({ language: langs[key] }, prompts[key]);
                logWithTime("ğŸ™ï¸ Using Twilio STT for EN/FR");
            }

            logWithTime("âœ… Sending name+date collection TwiML");
            requestTimer();
            res.setHeader("Content-Type", "text/xml");
            res.send(vr.toString());
            return;
        }

        /* ---- STEP 3 : Parse & Schedule ---- */
        if (step === "collect") {
            logWithTime("ğŸ“ STEP 3: Parsing Speech and Scheduling Appointment");
            const lang = req.query.lang || "1";
            let utterance = req.body.SpeechResult || "";
            const from = req.body.From || "";
            const recordingUrl = req.body.RecordingUrl;

            logWithTime(`ğŸŒ Language: ${lang === "1" ? "English" : lang === "2" ? "French" : "Hebrew"}`);
            logWithTime(`ğŸ“ From: ${from}`);
            logWithTime(`ğŸ™ï¸ Recording URL: ${recordingUrl || "N/A"}`);
            logWithTime(`ğŸ—£ï¸ Initial utterance (Twilio STT): "${utterance}"`);

            if (lang === "3" && recordingUrl) {
                logWithTime("ğŸ™ï¸ Hebrew mode â€” fetching & transcribing with Hugging Face Whisperâ€¦");
                utterance = await transcribeAudioFromTwilio(recordingUrl);
            }

            if (!utterance) {
                logWithTime("âš ï¸ No speech detected / transcription failed");
                vr.say({ language: "en-US" },
                    "Sorry, I could not understand your message. Please try again later."
                );
                requestTimer();
                res.setHeader("Content-Type", "text/xml");
                res.send(vr.toString());
                return;
            }

            logWithTime(`ğŸ§  Final extracted speech: "${utterance}"`);

            let whenISO, name;
            const currentYear = new Date().getFullYear();

            try {
                const gptTimer = timeStart("GPT-4o-mini parsing");
                const sysPrompt =
                    lang === "3" ?
                    `××ª×” ×¢×•×–×¨ ×§×‘×™×¢×ª ×ª×•×¨×™× ×¨×¤×•××™×™×. ××ª×•×š ×”××©×¤×˜ ×©×œ ×”××˜×•×¤×œ, ×”×¤×§ *×©× ××œ×* ×•-*×ª××¨×™×š ××“×•×™×§* (×›×•×œ×œ ×©×¢×” ×× ×§×™×™××ª).
×”× ×— ×©×”×©× ×” ×”× ×•×›×—×™×ª ×”×™× ${currentYear} ×× ×œ× ×¦×•×™×Ÿ ××—×¨×ª. ×”×—×–×¨ JSON ×ª×§×™×Ÿ ×‘×œ×‘×“:
{"date_iso":"YYYY-MM-DDTHH:mm:ssZ","name":"×©× ×”××˜×•×¤×œ"}.` :
                    `You are a medical appointment assistant.
Extract the patient's *full name* and the *exact date and time* from the sentence.
If no year is provided, assume it is ${currentYear}.
Return strict JSON only:
{"date_iso":"YYYY-MM-DDTHH:mm:ssZ","name":"Patient name"}.`;

                logWithTime("ğŸ¤– Calling GPT-4o-mini for parsing...");
                const completion = await openai.chat.completions.create({
                    model: "gpt-4o-mini",
                    messages: [
                        { role: "system", content: sysPrompt },
                        { role: "user", content: utterance },
                    ],
                    temperature: 0.1,
                });

                gptTimer();
                const data = JSON.parse(completion.choices[0].message.content.trim());
                whenISO = data.date_iso;
                name = data.name || "Patient";

                logWithTime(`âœ… GPT Parsed - Name: "${name}", Date: "${whenISO}"`);

                // SÃ©curitÃ© : remet l'annÃ©e courante si le modÃ¨le renvoie une annÃ©e passÃ©e
                const d = new Date(whenISO);
                if (d.getFullYear() < currentYear) {
                    logWithTime(`âš ï¸ Adjusting year from ${d.getFullYear()} to ${currentYear}`);
                    d.setFullYear(currentYear);
                    whenISO = d.toISOString();
                }
            } catch (e) {
                logWithTime("âš ï¸ OpenAI parsing error:", e.message);
                // Fallback: chrono pour EN/FR ; sinon valeur par dÃ©faut (J+1)
                const parsed =
                    lang === "1" || lang === "2" ?
                    chrono.parseDate(utterance, new Date(), { forwardDate: true }) :
                    null;

                whenISO = parsed ?
                    parsed.toISOString() :
                    new Date(Date.now() + 24 * 3600 * 1000).toISOString();
                name = "Patient";
                logWithTime(`âš ï¸ Fallback parsing - Name: "${name}", Date: "${whenISO}"`);
            }

            try {
                await createCalendarEvent({
                    summary: `${process.env.CLINIC_NAME} â€“ RDV ${name}`,
                    startISO: whenISO,
                    minutes: parseInt(process.env.DEFAULT_APPT_MINUTES || "30", 10),
                    phone: from,
                });

                if (lang === "3") {
                    // Confirmation audio prÃ©-enregistrÃ©e en hÃ©breu
                    logWithTime("ğŸ“¢ Playing Hebrew confirmation MP3");
                    vr.play("https://dentist-ivr-poc.vercel.app/audio/confirm-he.mp3");
                    const localized = new Date(whenISO).toLocaleString("en-US", {
                        timeZone: process.env.CLINIC_TIMEZONE,
                    });
                    vr.say({
                            language: "en-US",
                            voice: "Polly.Joanna",
                        },
                        `Appointment confirmed. Date and time ${localized}.`
                    );
                    logWithTime(`ğŸ“¢ Confirmation message: "Appointment confirmed. Date and time ${localized}."`);
                } else {
                    const msgs = {
                        "1": `Thank you ${name}. Your appointment has been scheduled for ${new Date(
              whenISO
            ).toLocaleString("en-US", { timeZone: process.env.CLINIC_TIMEZONE })}. Goodbye!`,
                        "2": `Merci ${name}. Votre rendez-vous a bien Ã©tÃ© enregistrÃ© pour le ${new Date(
              whenISO
            ).toLocaleString("fr-FR", { timeZone: process.env.CLINIC_TIMEZONE })}. Ã€ bientÃ´t !`,
                    };
                    logWithTime(`ğŸ“¢ Confirmation message: "${msgs[lang]}"`);
                    vr.say({ language: { "1": "en-US", "2": "fr-FR" }[lang] }, msgs[lang]);
                }
            } catch (err) {
                logWithTime("âŒ Calendar error:", err.message);
                vr.say({ language: "en-US" },
                    "Sorry, there was an issue scheduling your appointment."
                );
            }

            const totalRequestDuration = requestTimer();
            logWithTime("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
            logWithTime("âœ… REQUEST COMPLETED");
            logWithTime(`â±ï¸ TOTAL REQUEST TIME: ${totalRequestDuration}ms (${(totalRequestDuration/1000).toFixed(2)}s)`);
            logWithTime("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");

            res.setHeader("Content-Type", "text/xml");
            res.send(vr.toString());
            return;
        }
    } catch (err) {
        requestTimer();
        logWithTime("ğŸ”¥ FATAL ERROR:", err.message, err.stack);
        const fallback = new VoiceResponse();
        fallback.say({ language: "en-US" }, "Sorry, something went wrong on our end.");
        res.setHeader("Content-Type", "text/xml");
        res.send(fallback.toString());
    }
}